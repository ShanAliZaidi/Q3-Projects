{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-google-genai\n",
        "%pip install -qU langchain langchain_community"
      ],
      "metadata": {
        "id": "o9p8Vg4avXes"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini = userdata.get('GEMINI_KEY')\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = gemini\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.0-flash-exp\",\n",
        "    temperature = 0.1\n",
        ")"
      ],
      "metadata": {
        "id": "ktWjHmekwFaB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dNRnpgOguh-J"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import tool\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers.\n",
        "\n",
        "    Args:\n",
        "        a: First integer\n",
        "        b: Second integer\n",
        "    \"\"\"\n",
        "    print(\"add is called\")\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers.\n",
        "\n",
        "    Args:\n",
        "        a: First integer\n",
        "        b: Second integer\n",
        "    \"\"\"\n",
        "    print(\"mul is called\")\n",
        "    return a * b\n",
        "\n",
        "@tool\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract two integers.\n",
        "\n",
        "    Args:\n",
        "        a: First integer\n",
        "        b: Second integer\n",
        "    \"\"\"\n",
        "    print(\"sub is called\")\n",
        "    return a - b\n",
        "\n",
        "@tool\n",
        "def divide(a: int, b: int) -> int:\n",
        "    \"\"\"Divide two integers.\n",
        "\n",
        "    Args:\n",
        "        a: First integer\n",
        "        b: Second integer\n",
        "    \"\"\"\n",
        "    print(\"divide is called\")\n",
        "    return a / b\n",
        "\n",
        "@tool\n",
        "def llm_res(a: str) -> str:\n",
        "  \"\"\" Give general response from the LLM.\n",
        "\n",
        "  Args:\n",
        "    a: a simple query\n",
        "    \"\"\"\n",
        "  return llm.invoke(a).content\n",
        "\n",
        "tools = [add,subtract,multiply,divide]\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "prompt.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8uDoGmRPITq",
        "outputId": "e573b028-28b6-48bb-a846-06e508cf7a7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "executor = AgentExecutor(agent = agent, tools = tools, memory = memory)"
      ],
      "metadata": {
        "id": "19T9hfifOtd2"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    query = input(\"Calculator is on:(type 'off' to turn off) \")\n",
        "\n",
        "    # Break the loop if the user inputs \"off\"\n",
        "    if query.lower() == \"off\":\n",
        "        break\n",
        "\n",
        "    # Process the user's query\n",
        "    res = executor.invoke({\"input\": query})\n",
        "    print(res.get(\"output\"))\n",
        "\n",
        "print(\"Calculator is off.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmeQAz_BP8oI",
        "outputId": "1f58f64c-3eb9-4b18-8da0-9337367d6a4c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculator is on:(type 'off' to turn off) what is 10 time 7 and 100 added to it\n",
            "mul is called\n",
            "add is called\n",
            "10 times 7 is 70, and 100 added to that is 170.\n",
            "Calculator is on:(type 'off' to turn off) off\n",
            "Calculator is off.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.load_memory_variables({}).get(\"history\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoVZgp5F1_g-",
        "outputId": "fa6ac295-14f0-4d1e-f03b-cb2c135db86b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: 90 - 65\n",
            "AI: 25\n",
            "Human: 30-8\n",
            "AI: 22\n",
            "Human: what is langchain\n",
            "AI: I am sorry, I cannot provide information about Langchain. My capabilities are limited to performing calculations using the provided tools.\n",
            "Human: \n",
            "AI: I can perform addition, subtraction, multiplication, and division. What would you like to calculate?\n",
            "Human: 1-0\n",
            "AI: 1\n",
            "Human: 45/9\n",
            "AI: 45 / 9 = 5\n",
            "Human: what is 10 time 7 and 100 added to it\n",
            "AI: 10 times 7 is 70, and 100 added to that is 170.\n"
          ]
        }
      ]
    }
  ]
}